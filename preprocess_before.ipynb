{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0755bdf3",
   "metadata": {},
   "source": [
    "# **Preprocessing sequences before passing to dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765408f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from preprocessing.preprocessing_functions import (\n",
    "    reindex_frames,\n",
    "    handle_missing_face,\n",
    "    handle_missing_hands,\n",
    "    fill_missing_hands,\n",
    "    drop_sequences_by_missing_face,\n",
    "    resample_sequence,\n",
    "    center_around_nose,\n",
    "    scale_by_shoulder_width,\n",
    "    scale_by_shoulder_width_2,\n",
    "    center_around_nose_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e483b",
   "metadata": {},
   "source": [
    "## **1st attempt 250 classes with really low sequence count**\n",
    "\n",
    "Horrible accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d90a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign\n",
      "listen    415\n",
      "look      412\n",
      "donkey    410\n",
      "hear      405\n",
      "mouse     405\n",
      "         ... \n",
      "dance     312\n",
      "person    312\n",
      "beside    310\n",
      "vacuum    307\n",
      "zipper    299\n",
      "Name: count, Length: 250, dtype: int64\n",
      "94134\n",
      "sign\n",
      "see        57\n",
      "uncle      55\n",
      "kitty      54\n",
      "radio      53\n",
      "grandpa    53\n",
      "           ..\n",
      "tooth      26\n",
      "person     25\n",
      "garbage    25\n",
      "orange     24\n",
      "horse      21\n",
      "Name: count, Length: 250, dtype: int64\n",
      "9413\n"
     ]
    }
   ],
   "source": [
    "df_metadata = pd.read_csv('dataset/train_clean_50_threshhold.csv')\n",
    "print(df_metadata['sign'].value_counts())\n",
    "print(len(df_metadata))\n",
    "\n",
    "df_subset = df_metadata.sample(n=len(df_metadata)//10, random_state=99)\n",
    "#df_subset = df_metadata.groupby('sign', group_keys=False).apply(\n",
    "#    lambda x: x.sample(frac=0.05, random_state=99)\n",
    "#).reset_index(drop=True)\n",
    "print(df_subset['sign'].value_counts())\n",
    "print(len(df_subset))\n",
    "\n",
    "#df_subset.to_csv('dataset/train_clean_50_threshhold_10_percent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19133c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   0%|          | 0/9413 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 9413/9413 [54:00<00:00,  2.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_metadata = pd.read_csv('dataset/train_clean_50_threshhold_10_percent.csv')\n",
    "output_dir = Path('dataset/processed_30frame_test')\n",
    "target_frames = 30\n",
    "\n",
    "\n",
    "df_iter = tqdm(df_metadata.iterrows(), total=len(df_metadata), desc=\"Preprocessing\")\n",
    "for idx, row in df_iter:\n",
    "    df = pd.read_parquet(Path('asl-signs') / row['path'])\n",
    "    \n",
    "    # all\n",
    "    df = reindex_frames(df)\n",
    "\n",
    "    df = handle_missing_face(df)\n",
    "    df = handle_missing_hands(df)\n",
    "\n",
    "    df = center_around_nose_2(df)\n",
    "    df = scale_by_shoulder_width_2(df)\n",
    "\n",
    "    df = fill_missing_hands(df)\n",
    "\n",
    "    df = resample_sequence(df, target_frames=target_frames)\n",
    "    \n",
    "    # Save\n",
    "    features = df[['x', 'y', 'z']].values.reshape(target_frames, -1)\n",
    "    np.save(output_dir / f\"{row['sequence_id']}.npy\", features)\n",
    "\n",
    "\n",
    "print('Preprocessing complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'processed_30frame_test'\n",
    "\n",
    "df_meta = pd.read_csv('dataset/train_clean_50_threshhold_10_percent.csv')\n",
    "\n",
    "df_meta['path'] = df_meta['sequence_id'].apply(lambda sid: f'{folder}/{sid}.npy')\n",
    "\n",
    "# save\n",
    "df_meta.to_csv(\"dataset/train_clean_50_threshhold_10_percent_modified_path.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21247aa",
   "metadata": {},
   "source": [
    "\n",
    "### Training\n",
    "\n",
    "Epoch 50/100                                                                 \n",
    "Train Loss: 1.9671 | Train Acc: 0.4914\n",
    "Val Loss:   4.8743 | Val Acc:   0.1817\n",
    "\n",
    "Epoch 51/100                                                        \n",
    "Train Loss: 1.9337 | Train Acc: 0.5039\n",
    "Val Loss:   4.9290 | Val Acc:   0.1700\n",
    "\n",
    "Epoch 52/100                                                                             \n",
    "Train Loss: 1.9126 | Train Acc: 0.5092\n",
    "Val Loss:   4.9257 | Val Acc:   0.1870\n",
    "\n",
    "Horrible accuracy, overfitting, all in all bad but considering there are 250 overall signs and only 40-20 sequences for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d443ecf9",
   "metadata": {},
   "source": [
    "## **2nd attempt 25 signs and all of their sequences** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff29419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign\n",
      "listen    415\n",
      "look      412\n",
      "donkey    410\n",
      "hear      405\n",
      "mouse     405\n",
      "Name: count, dtype: int64\n",
      "94134\n",
      "sign\n",
      "listen    415\n",
      "look      412\n",
      "donkey    410\n",
      "uncle     405\n",
      "mouse     405\n",
      "Name: count, dtype: int64\n",
      "10051\n"
     ]
    }
   ],
   "source": [
    "df_metadata = pd.read_csv('dataset/train_clean_50_threshhold.csv')\n",
    "print(df_metadata['sign'].value_counts().head(5))\n",
    "print(len(df_metadata))\n",
    "\n",
    "top_25_signs = df_metadata['sign'].value_counts().head(25).index.tolist()\n",
    "df_subset = df_metadata[df_metadata['sign'].isin(top_25_signs)].reset_index(drop = True)\n",
    "\n",
    "print(df_subset['sign'].value_counts().head(5))\n",
    "print(len(df_subset))\n",
    "\n",
    "df_subset.to_csv('dataset/train_clean_50_threshhold_25_signs_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43a605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 10051/10051 [1:09:25<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_metadata = pd.read_csv('dataset/train_clean_50_threshhold_25_signs_all.csv')\n",
    "output_dir = Path('dataset/processed_60frame_25_signs')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "target_frames = 60\n",
    "\n",
    "\n",
    "df_iter = tqdm(df_metadata.iterrows(), total=len(df_metadata), desc=\"Preprocessing\")\n",
    "for idx, row in df_iter:\n",
    "    df = pd.read_parquet(Path('asl-signs') / row['path'])\n",
    "    \n",
    "    # all\n",
    "    df = reindex_frames(df)\n",
    "\n",
    "    df = handle_missing_face(df)\n",
    "    df = handle_missing_hands(df)\n",
    "\n",
    "    df = center_around_nose_2(df)\n",
    "    df = scale_by_shoulder_width_2(df)\n",
    "\n",
    "    df = fill_missing_hands(df)\n",
    "\n",
    "    df = resample_sequence(df, target_frames=target_frames)\n",
    "    \n",
    "    # Save\n",
    "    features = df[['x', 'y', 'z']].values.reshape(target_frames, -1)\n",
    "    np.save(output_dir / f\"{row['sequence_id']}.npy\", features)\n",
    "\n",
    "\n",
    "print('Preprocessing complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0117b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'processed_60frame_25_signs'\n",
    "\n",
    "df_meta = pd.read_csv('dataset/train_clean_50_threshhold_25_signs_all.csv')\n",
    "\n",
    "df_meta['path'] = df_meta['sequence_id'].apply(lambda sid: f'{folder}/{sid}.npy')\n",
    "\n",
    "# save\n",
    "df_meta.to_csv('dataset/train_clean_50_threshhold_25_signs_all_modified_path.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c7c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of signs: 25\n",
      "New label mapping:\n",
      "{'awake': 0, 'brown': 1, 'bye': 2, 'cat': 3, 'cow': 4, 'donkey': 5, 'duck': 6, 'fireman': 7, 'first': 8, 'hear': 9, 'lips': 10, 'listen': 11, 'look': 12, 'make': 13, 'mouse': 14, 'nuts': 15, 'pen': 16, 'pretend': 17, 'shhh': 18, 'sleepy': 19, 'think': 20, 'toothbrush': 21, 'uncle': 22, 'wake': 23, 'yesterday': 24}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_25_signs = pd.read_csv('dataset/train_clean_50_threshhold_25_signs_all_modified_path.csv')\n",
    "\n",
    "\n",
    "unique_signs = sorted(df_25_signs['sign'].unique())\n",
    "print(f'signs: {len(unique_signs)}')\n",
    "\n",
    "label_mapping_25_signs = {sign: idx for idx, sign in enumerate(unique_signs)}\n",
    "\n",
    "print('new mapping:')\n",
    "print(label_mapping_25_signs)\n",
    "\n",
    "\n",
    "\n",
    "with open('dataset/label_mapping_25.json', 'w') as f:\n",
    "    json.dump(label_mapping_25_signs, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e900841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "listen        415\n",
       "look          412\n",
       "donkey        410\n",
       "uncle         405\n",
       "mouse         405\n",
       "hear          405\n",
       "cow           404\n",
       "bye           402\n",
       "lips          402\n",
       "pretend       402\n",
       "duck          401\n",
       "wake          401\n",
       "sleepy        401\n",
       "fireman       400\n",
       "toothbrush    400\n",
       "shhh          400\n",
       "think         399\n",
       "pen           399\n",
       "brown         399\n",
       "awake         399\n",
       "first         398\n",
       "nuts          398\n",
       "yesterday     398\n",
       "cat           398\n",
       "make          398\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_25_signs['sign'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
